{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations for nine key structures (thalami, midbrain, palate, 4th ventricle, cisterna magna, nuchal translucency (NT), nasal tip, nasal skin, and nasal bone) could be found in ObjectDetection.xlsx file.The column names in ObjectDetection.xlsx file are the image name, structure name and xy min max coordinates of the structure in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuexN6tyOu9k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install plotlib opencv-python openpyxl scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuexN6tyOu9k"
   },
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.chdir (\"./Jaik's Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuexN6tyOu9k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.transforms import transforms, v2\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.cuda as cuda\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib.patches import Rectangle\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "Please ensure that you download the zip file folders from the [google drive](https://drive.google.com/file/d/1-ppPA9UHw9ZTBxyGmbWEyCgRNKTECC_6/view?usp=drive_link) and add it to the root folder of this directory before running the below code cell.\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zx2hdcTZfG5j"
   },
   "outputs": [],
   "source": [
    "data_dir=Path(\"Fetus_Health_Dataset/allStandard\")\n",
    "labels_file=Path(\"ObjectDetection.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4xUfo0VzanD"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9FzIYzAQVm4"
   },
   "outputs": [],
   "source": [
    "def read_dataset(data_dir, labels_file):\n",
    "    labels_df = pd.read_excel(labels_file)\n",
    "\n",
    "    #Map the different labels to ints in order to train\n",
    "    label_map = {\n",
    "            'thalami': 0,\n",
    "            'nasal bone': 1,\n",
    "            'palate': 2,\n",
    "            'nasal skin': 3,\n",
    "            'nasal tip': 4,\n",
    "            'midbrain': 5,\n",
    "            'NT': 6,\n",
    "            'IT': 7,\n",
    "            'CM': 8 }\n",
    "\n",
    "    #Loop through the excel sheet to make sure each image exist (not all is used)\n",
    "    mask = labels_df.apply(lambda x: os.path.exists(os.path.join(data_dir, x[\"fname\"])), axis=1)\n",
    "    labels_df = labels_df[mask]\n",
    "\n",
    "    #Create image paths in order to read into model\n",
    "    image_paths = [Path(data_dir) / fname for fname in labels_df[\"fname\"]]\n",
    "\n",
    "    #Add all the classes\n",
    "    labels = [label_map[name] for name in labels_df[\"structure\"]]\n",
    "    og_shapes = []\n",
    "\n",
    "    #Progress bar\n",
    "    for image_path in tqdm(image_paths, desc=\"Loading Images\", total=len(image_paths)):\n",
    "        img = cv2.imread(str(image_path))\n",
    "        height, width, _ = img.shape\n",
    "        og_shapes.append((width, height))\n",
    "\n",
    "    #Read bounding boxes\n",
    "    bboxes = labels_df.iloc[:, 2:6].values.astype(float)\n",
    "\n",
    "    #Format data into dataframe\n",
    "    data = {\n",
    "        'filepath': image_paths,\n",
    "        'width': [shape[0] for shape in og_shapes],\n",
    "        'height': [shape[1] for shape in og_shapes],\n",
    "        'class': labels,\n",
    "        'xmin': bboxes[:, 1],\n",
    "        'ymin': bboxes[:, 0],\n",
    "        'xmax': bboxes[:, 3],\n",
    "        'ymax': bboxes[:, 2]\n",
    "    }\n",
    "\n",
    "    df_data = pd.DataFrame(data)\n",
    "\n",
    "    return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwYm2UWzjWUZ",
    "outputId": "9b03707a-af9d-4bfd-86d3-532f9a432c49"
   },
   "outputs": [],
   "source": [
    "df_train = read_dataset(data_dir, labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_BlTpZCuVqf"
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    return cv2.imread(str(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSxm4n1TuXmc"
   },
   "outputs": [],
   "source": [
    "def create_mask(bb, x):\n",
    "    #Creates a mask for the bounding box of same shape as image\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    bb = bb.astype(np.int32)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    #Convert mask Y to a bounding box \n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0:\n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n",
    "\n",
    "def create_bb_array(x):\n",
    "    #Generates bounding box array from df_train row\n",
    "    return np.array([x[5],x[4],x[7],x[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYwuZCkQubOi"
   },
   "outputs": [],
   "source": [
    "def resize_image_bb(read_path,write_path,bb,sz):\n",
    "    #Resize an image and its bounding box\n",
    "    #Write image to new path (leave original dataset intact)\n",
    "    im = read_image(read_path)\n",
    "    new_path = write_path/read_path.parts[-1]\n",
    "    if new_path.exists():\n",
    "        im_resized = read_image(new_path)\n",
    "    else:\n",
    "        im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
    "        cv2.imwrite(new_path, im_resized)\n",
    "    \n",
    "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
    "    return new_path, mask_to_bb(Y_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "CfP8ZQfluceI",
    "outputId": "f314ead4-f1d3-4cd9-ecf5-b0fecdb11094"
   },
   "outputs": [],
   "source": [
    "new_paths = []\n",
    "new_bbs = []\n",
    "train_path_resized = Path('image_resized')\n",
    "\n",
    "#Progress Bar\n",
    "for index, row in tqdm(df_train.iterrows(), desc=\"Resizing Images\",total=df_train.shape[0]):\n",
    "    new_path,new_bb = resize_image_bb(row['filepath'], train_path_resized, create_bb_array(row.values),300)\n",
    "    new_paths.append(new_path)\n",
    "    new_bbs.append(new_bb)\n",
    "\n",
    "#Update image path and boxes\n",
    "df_train['new_path'] = new_paths\n",
    "df_train['new_bb'] = new_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13bc5QSRyCcu"
   },
   "outputs": [],
   "source": [
    "def crop(im, r, c, target_r, target_c):\n",
    "    return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "# Random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA0kMwWWyc5D"
   },
   "outputs": [],
   "source": [
    "def rotate_cv(im, deg, y=False, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    #Rotates an image by deg degrees\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "    if y:\n",
    "        return cv2.warpAffine(im, M,(c,r), borderMode=cv2.BORDER_CONSTANT)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n",
    "\n",
    "def random_cropXY(x, Y, r_pix=8):\n",
    "    #Returns a random crop\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    xx = crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    YY = crop(Y, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    return xx, YY\n",
    "\n",
    "def transformsXY(path, bb, transforms):\n",
    "    #Read image, convert formate, and create a mask\n",
    "    x = cv2.imread(str(path)).astype(np.float32)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "    Y = create_mask(bb, x)\n",
    "\n",
    "    #Apply trasformations such as flips and rotates\n",
    "    if transforms:\n",
    "        rdeg = (np.random.random()-.50)*20\n",
    "        x = rotate_cv(x, rdeg)\n",
    "        Y = rotate_cv(Y, rdeg, y=True)\n",
    "        if np.random.random() > 0.5:\n",
    "            x = np.fliplr(x).copy()\n",
    "            Y = np.fliplr(Y).copy()\n",
    "        x, Y = random_cropXY(x, Y)\n",
    "    else:\n",
    "        x, Y = center_crop(x), center_crop(Y)\n",
    "    return x, mask_to_bb(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rObZ29PJyfUH"
   },
   "outputs": [],
   "source": [
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n",
    "                         fill=False, lw=3)\n",
    "\n",
    "def show_corner_bb(im, bb):\n",
    "    plt.imshow(im)\n",
    "    plt.gca().add_patch(create_corner_rect(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYIMc2Ggyh_0"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qa58hfTpymFB"
   },
   "outputs": [],
   "source": [
    "#Create training, validation, and test set\n",
    "X_train, X_val_temp, y_train, y_val_temp = train_test_split(df_train[['new_path', 'new_bb']], df_train['class'], test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_temp, y_val_temp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shm2Q-fwyrno"
   },
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    #Normalise images\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im - imagenet_stats[0])/imagenet_stats[1]\n",
    "\n",
    "def unnormalize(im):\n",
    "    #Unnormalise images for printing\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return im * imagenet_stats[1, np.newaxis, np.newaxis] + imagenet_stats[0, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcbjgAV_yth7"
   },
   "outputs": [],
   "source": [
    "#Pass image data set to edit images\n",
    "class FetusDataset(Dataset):\n",
    "    def __init__(self, paths, bb, y, transforms=False):\n",
    "        self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bb = bb.values\n",
    "        self.y = y.values\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
    "        x = normalize(x)\n",
    "        x = np.rollaxis(x, 2)\n",
    "        return x, y_class, y_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNNuEtGVyvRM"
   },
   "outputs": [],
   "source": [
    "train_ds = FetusDataset(X_train['new_path'],X_train['new_bb'] ,y_train, transforms=True)\n",
    "valid_ds = FetusDataset(X_val['new_path'],X_val['new_bb'],y_val)\n",
    "test_ds = FetusDataset(X_test['new_path'],X_test['new_bb'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHc13f-PywrB"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "#Create dataloaders for training set\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j82334Fpy3iC"
   },
   "outputs": [],
   "source": [
    "#Model to train bounding box\n",
    "class BB_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB_model, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        \n",
    "        #Retrain last 8 layers\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        # self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        \n",
    "        #Train\n",
    "        self.bb_norm = nn.BatchNorm1d(512)\n",
    "        self.bb = nn.ModuleList([nn.Linear(512, 4) for i in range(0,9)])\n",
    "\n",
    "    def forward(self, x, y_class=None):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.bb_norm(x)\n",
    "        if y_class is None: ## Use None to get all 9 boxes\n",
    "            return torch.cat([self.bb[i](x) for i in range(9)], dim=-1)\n",
    "        out = torch.empty(x.shape[0], 4, device=x.device)\n",
    "        for cls in range(9):\n",
    "            idx = (y_class == cls).nonzero()\n",
    "            out[idx, ...] = self.bb[cls](x[idx, ...])\n",
    "        return out\n",
    "        # return torch.stack([self.bb[cls](x[i:i+1, ...]) for i, cls in enumerate(y_class)]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH2a4x15y6Kk"
   },
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEJzFOM_y7gN"
   },
   "outputs": [],
   "source": [
    "# def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
    "#     # with torch.no_grad():\n",
    "#     #     val_loss, val_oui, val_dist = val_metrics(model, valid_dl)\n",
    "#     for i in range(epochs):\n",
    "#         model.train()\n",
    "#         total = 0\n",
    "#         sum_loss = 0\n",
    "#         for x, y_class, y_bb in tqdm(train_dl, desc=f\"Epoch {i+1}/{epochs}\"):\n",
    "#             batch = y_class.shape[0]\n",
    "#             x = x.to(device).float()\n",
    "#             #y_class = y_class.to(device)\n",
    "#             y_bb = y_bb.to(device).float()\n",
    "#             boxes = model(x, y_class)\n",
    "#             # loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "#             # print(boxes.shape, y_bb.shape)\n",
    "#             # pred_y_bb = torch.gather(boxes, -1, y_class[:, None, None].repeat(1, 4, 1))\n",
    "#             loss_bb = F.l1_loss(boxes, y_bb, reduction=\"none\").sum(1)\n",
    "#             loss_bb = loss_bb.sum()\n",
    "#             loss = loss_bb\n",
    "#             sum_loss +=  loss.detach().cpu().item()\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total += batch\n",
    "#         train_loss = sum_loss/total\n",
    "#         with torch.no_grad():\n",
    "#             val_loss, val_oui, val_dist = val_metrics(model, valid_dl)\n",
    "#         torch.save(model.state_dict(), 'model_v5.pth')\n",
    "#         print(\"train_loss %.3f val_loss %.3f val_iou %.3f val_dist %.3f\" % (train_loss, val_loss, val_oui, val_dist))\n",
    "#     return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEJzFOM_y7gN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10, C=1000):\n",
    "    train_losses = []\n",
    "    val_distces = []\n",
    "    val_ious = []\n",
    "    val_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for x, y_class, y_bb in tqdm(train_dl, desc=f\"Epoch {i+1}/{epochs}\"):\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.to(device).float()\n",
    "            y_bb = y_bb.to(device).float()\n",
    "            boxes = model(x, y_class)\n",
    "            loss_bb = F.l1_loss(boxes, y_bb, reduction=\"none\").sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "            loss = loss_bb\n",
    "            sum_loss += loss.detach().cpu().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += batch\n",
    "\n",
    "        # Calculate training loss\n",
    "        train_loss = sum_loss / total\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Calculate validation loss\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_oui, val_dist = val_metrics(model, valid_dl)\n",
    "            val_losses.append(val_loss)\n",
    "            val_ious.append(val_oui)\n",
    "            val_distces.append(val_dist)\n",
    "        \n",
    "        # Save model after each epoch\n",
    "        torch.save(model.state_dict(), 'model_v5.pth')\n",
    "\n",
    "        # Print and log the losses\n",
    "        print(\"Epoch %d/%d: train_loss %.3f val_loss %.3f val_iou %.3f val_dist %.3f\" % (\n",
    "            i+1, epochs, train_loss, val_loss, val_oui, val_dist))\n",
    "        \n",
    "    # Plotting validation and test losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plotting distance and IoU\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([val_dist.cpu() for val_dist in val_distces], label='Validation Distance')  # Moving tensors to CPU\n",
    "    plt.plot([val_iou.cpu() for val_iou in val_ious], label='Validation Intersection')   # Moving tensors to CPU\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Validation Distance and Intersection over Union (IoU)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBre-4wMy84U"
   },
   "outputs": [],
   "source": [
    "# def val_metrics(model, valid_dl, C=1000):\n",
    "#     model.eval()\n",
    "#     total = 0\n",
    "#     sum_loss = 0\n",
    "#     correct = 0\n",
    "#     for x, y_class, y_bb in valid_dl:\n",
    "#         batch = y_class.shape[0]\n",
    "#         x = x.to(device).float()\n",
    "#         y_class = y_class.to(device)\n",
    "#         y_bb = y_bb.to(device).float()\n",
    "#         out_class, out_bb = model(x)\n",
    "#         loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "#         loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "#         loss_bb = loss_bb.sum()\n",
    "#         loss = loss_class + loss_bb/C\n",
    "#         _, pred = torch.max(out_class, 1)\n",
    "#         correct += pred.eq(y_class).sum().item()\n",
    "#         sum_loss += loss.item()\n",
    "#         total += batch\n",
    "#     return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MRcmDt25_Oh"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision.ops import box_iou, distance_box_iou\n",
    "\n",
    "def center_xy(bboxes):\n",
    "    #Compute the center (x, y) coordinates of bounding boxes\n",
    "    return (bboxes[:, :2] + bboxes[:, 2:]) / 2\n",
    "\n",
    "def bbox_center_distance(bbox1, bbox2):\n",
    "    #Calculate the distance between the centers of two bounding boxes\n",
    "    center1 = center_xy(bbox1)\n",
    "    center2 = center_xy(bbox2)\n",
    "    return torch.norm(center1 - center2, dim=1)\n",
    "\n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    iou_total = 0\n",
    "    dist_total = 0\n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.to(device).float()\n",
    "        # y_class = y_class.to(device)\n",
    "        y_bb = y_bb.to(device).float()\n",
    "        bboxes = model(x, y_class)\n",
    "        # loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "        # pred_y_bb = torch.gather(boxes, -1, y_class[:, None, None].repeat(1, 4, 1))\n",
    "        loss_bb = F.l1_loss(bboxes, y_bb, reduction=\"sum\")\n",
    "        loss = loss_bb\n",
    "        \n",
    "        iou = (box_iou(bboxes, y_bb) * torch.eye(batch, device=bboxes.device)).sum()\n",
    "        iou_total += iou\n",
    "\n",
    "        dist = bbox_center_distance(bboxes, y_bb).sum()\n",
    "        dist_total += dist\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "    return sum_loss/total, iou_total/total, dist/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHC6vWryy-aq"
   },
   "outputs": [],
   "source": [
    "model = BB_model().to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjC4pLqqy_dV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the function below, some outputs with bbox annotations are saved as EXAMPLE_x_test_model.png files in the Example_Output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RA-jTRDF23ZS"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_dl, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y_class, y_bb in test_dl:\n",
    "            x = x.to(device).float()\n",
    "            y_class = y_class.to(device)\n",
    "            y_bb = y_bb.cpu().float()\n",
    "            bboxes = model(x)\n",
    "            bboxes = bboxes.reshape(x.shape[0], 9, 4)\n",
    "            for i in range(x.shape[0]):\n",
    "                img = x[i].permute(1, 2, 0).cpu().numpy()  \n",
    "                img = unnormalize(img)\n",
    "                y_bbox = y_bb[i, ...].numpy()\n",
    "                # print(bboxes[y_class[i]], y_class[i])\n",
    "                bbox = bboxes[i, y_class[i], ...].cpu().numpy()\n",
    "    \n",
    "                # Plot image\n",
    "                plt.imshow(img)\n",
    "                ax = plt.gca()\n",
    "\n",
    "                # True bounding box\n",
    "                true_xmin, true_ymin, true_xmax, true_ymax = y_bbox\n",
    "                true_width = true_xmax - true_xmin\n",
    "                true_height = true_ymax - true_ymin\n",
    "                true_rect = plt.Rectangle((true_xmin, true_ymin), true_width, true_height,\n",
    "                                          linewidth=2, edgecolor='g', facecolor='none',)\n",
    "                ax.add_patch(true_rect)\n",
    "\n",
    "                # Predicted bounding box\n",
    "                pred_xmin, pred_ymin, pred_xmax, pred_ymax = bbox\n",
    "                pred_width = pred_xmax - pred_xmin\n",
    "                pred_height = pred_ymax - pred_ymin\n",
    "                pred_rect = plt.Rectangle((pred_xmin, pred_ymin), pred_width, pred_height,\n",
    "                                          linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(pred_rect)\n",
    "                plt.title(str(y_class[i].item()))\n",
    "\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9B7LaKXI4lvH"
   },
   "outputs": [],
   "source": [
    "test_model(model, train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
