{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing cv2: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing cv2: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.transforms import transforms, v2\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "# from torchmetrics.detection import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.cuda as cuda\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetusDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FetusDetector, self).__init__()\n",
    "        resnet = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "\n",
    "    def forward(self, image, box):\n",
    "        x = self.features1(image)\n",
    "        x = self.features2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # x = torch.cat((x, box), dim=1)\n",
    "        bbox_logits = self.bb(x)\n",
    "        return bbox_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetusDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels_df = pd.read_excel(labels_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'thalami': 0,\n",
    "            'nasal bone': 1,\n",
    "            'palate': 2,\n",
    "            'nasal skin': 3,\n",
    "            'nasal tip': 4,\n",
    "            'midbrain': 5,\n",
    "            'NT': 6,\n",
    "            'IT': 7,\n",
    "            'CM': 8\n",
    "        }\n",
    "\n",
    "        self.transform_PIL = transforms.Compose([\n",
    "            transforms.ToPILImage()\n",
    "        ])\n",
    "\n",
    "        self.transform_tensor = transforms.Compose([\n",
    "            transforms.PILToTensor()\n",
    "        ])\n",
    "\n",
    "        # Filter out rows with non-existing image files\n",
    "        self.labels_df = self.labels_df[self.labels_df.apply(lambda x: os.path.exists(os.path.join(self.data_dir, x[\"fname\"])), axis=1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_dir, self.labels_df.iloc[idx, 0])\n",
    "        image = read_image(path=image_path, mode=ImageReadMode.RGB).float().cuda()\n",
    "        # og_h, og_w = image.shape[1:]\n",
    "\n",
    "        image = self.transform(image)\n",
    "        n_h, n_w = image.shape[1:]\n",
    "\n",
    "        rows = self.labels_df[self.labels_df.iloc[:, 0] == self.labels_df.iloc[idx, 0]]\n",
    "\n",
    "        data = []\n",
    "        for _, row in rows.iterrows():\n",
    "            h_min, w_min, h_max, w_max = row[2:6].values.astype(float)\n",
    "            # w_min *= (n_w / og_w)\n",
    "            # h_min *= (n_h / og_h)\n",
    "            # w_max *= (n_w / og_w)\n",
    "            # h_max *= (n_h / og_h)\n",
    "            # boxes = torch.tensor([[w_min, h_min, w_max, h_max]], dtype=torch.float32)\n",
    "\n",
    "            data.append([self.labels_df.iloc[idx, 0], n_w, n_h, self.label_map.get(row[1]), w_min, h_min, w_max, h_max])\n",
    "\n",
    "        df_data = pd.DataFrame(data, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "        return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(bb, x):\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    bb = bb.astype(np.int)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0:\n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n",
    "\n",
    "def create_bb_array(x):\n",
    "    return np.array([x[5],x[4],x[7],x[6]])\n",
    "\n",
    "def resize_image_bb(read_path,write_path,bb,sz):\n",
    "    \"\"\"Resize an image and its bounding box and write image to new path\"\"\"\n",
    "    im = read_image(read_path)\n",
    "    im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
    "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
    "    new_path = str(write_path/read_path.parts[-1])\n",
    "    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n",
    "    return new_path, mask_to_bb(Y_resized)\n",
    "\n",
    "#Populating Training DF with new paths and bounding boxes\n",
    "new_paths = []\n",
    "new_bbs = []\n",
    "train_path_resized = Path('./road_signs/images_resized')\n",
    "for index, row in df_train.iterrows():\n",
    "    new_path,new_bb = resize_image_bb(row['filename'], train_path_resized, create_bb_array(row.values),300)\n",
    "    new_paths.append(new_path)\n",
    "    new_bbs.append(new_bb)\n",
    "df_train['new_path'] = new_paths\n",
    "df_train['new_bb'] = new_bbs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from fast.ai\n",
    "def crop(im, r, c, target_r, target_c):\n",
    "    return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "# random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_cv(im, deg, y=False, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "    if y:\n",
    "        return cv2.warpAffine(im, M,(c,r), borderMode=cv2.BORDER_CONSTANT)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n",
    "\n",
    "def random_cropXY(x, Y, r_pix=8):\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    xx = crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    YY = crop(Y, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "    return xx, YY\n",
    "\n",
    "def transformsXY(path, bb, transforms):\n",
    "    x = cv2.imread(str(path)).astype(np.float32)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "    Y = create_mask(bb, x)\n",
    "    if transforms:\n",
    "        rdeg = (np.random.random()-.50)*20\n",
    "        x = rotate_cv(x, rdeg)\n",
    "        Y = rotate_cv(Y, rdeg, y=True)\n",
    "        if np.random.random() > 0.5:\n",
    "            x = np.fliplr(x).copy()\n",
    "            Y = np.fliplr(Y).copy()\n",
    "        x, Y = random_cropXY(x, Y)\n",
    "    else:\n",
    "        x, Y = center_crop(x), center_crop(Y)\n",
    "    return x, mask_to_bb(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n",
    "                         fill=False, lw=3)\n",
    "\n",
    "def show_corner_bb(im, bb):\n",
    "    plt.imshow(im)\n",
    "    plt.gca().add_patch(create_corner_rect(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadDataset(Dataset):\n",
    "    def __init__(self, paths, bb, y, transforms=False):\n",
    "        self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bb = bb.values\n",
    "        self.y = y.values\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
    "        x = normalize(x)\n",
    "        x = np.rollaxis(x, 2)\n",
    "        return x, y_class, y_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RoadDataset(X_train['new_path'],X_train['new_bb'] ,y_train, transforms=True)\n",
    "valid_ds = RoadDataset(X_val['new_path'],X_val['new_bb'],y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your data and labels file\n",
    "data_dir = 'Dataset for Fetus Framework\\Training\\Standard'\n",
    "labels_file = 'ObjectDetection.xlsx'\n",
    "\n",
    "# Define transform for data augmentation and normalization\n",
    "transform = v2.Compose([\n",
    "    v2.Resize(size=(470, 650))\n",
    "])\n",
    "\n",
    "# Load the dataset and split into training and validation sets\n",
    "dataset = FetusDataset(data_dir, labels_file, transform=transform)\n",
    "\n",
    "# Check if any samples are left in the dataset\n",
    "if not dataset:\n",
    "    raise ValueError(\"No valid samples found in the dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADL_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
